{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio final: Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from util import print_eval\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from util import print_short_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_files('reviews_sentoken', shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División: Train y Dev\n",
    "\n",
    "Haremos el siguiente split:\n",
    "  - Train: 85% \n",
    "  - Dev: 15% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero extraemos Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(\n",
    "    dataset.data,\n",
    "    dataset.target,\n",
    "    test_size=0.25,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(802, 268)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0: 389, 1: 413}), Counter({0: 146, 1: 122}))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train), Counter(y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer +  LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', LinearSVC(random_state=0)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip..., max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t1.00\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       1.00      1.00      1.00       389\n",
      "        pos       1.00      1.00      1.00       413\n",
      "\n",
      "avg / total       1.00      1.00      1.00       802\n",
      "\n",
      "[[389   0]\n",
      " [  0 413]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print_eval(pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.82\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.82      0.86      0.84       146\n",
      "        pos       0.82      0.77      0.79       122\n",
      "\n",
      "avg / total       0.82      0.82      0.82       268\n",
      "\n",
      "[[125  21]\n",
      " [ 28  94]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test con algo nuestro..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this bad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this is good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this is very very good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this movie is not bad, it is good'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1er Experimento: Binarizar Conteos\n",
    "\n",
    "Probemos con **binary=True** a ver si se arregla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.80\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.81      0.84      0.82       146\n",
      "        pos       0.79      0.76      0.78       122\n",
      "\n",
      "avg / total       0.80      0.80      0.80       268\n",
      "\n",
      "[[122  24]\n",
      " [ 29  93]]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(binary=True)),\n",
    "    ('clf', LinearSVC(random_state=0)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "print_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test con algo nuestro nuevamente..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this bad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this is good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this is very very good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this movie is not bad, it is good'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distintos Modelos de Clasificación\n",
    "\n",
    "Probamos distintos modelos de clasificación usando los valores por defecto.\n",
    "\n",
    "Evaluamos en train (bias) y en dev (variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [\n",
    "    KNeighborsClassifier(),\n",
    "    MultinomialNB(),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    LogisticRegression(random_state=0),\n",
    "    LinearSVC(random_state=0),\n",
    "    SVC(random_state=0),\n",
    "    RandomForestClassifier(random_state=0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "accuracy\t0.74\tmacro f1\t0.73\n",
      "accuracy\t0.56\tmacro f1\t0.50\n",
      "<class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "accuracy\t0.98\tmacro f1\t0.98\n",
      "accuracy\t0.82\tmacro f1\t0.82\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "accuracy\t1.00\tmacro f1\t1.00\n",
      "accuracy\t0.66\tmacro f1\t0.66\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "accuracy\t1.00\tmacro f1\t1.00\n",
      "accuracy\t0.83\tmacro f1\t0.83\n",
      "<class 'sklearn.svm.classes.LinearSVC'>\n",
      "accuracy\t1.00\tmacro f1\t1.00\n",
      "accuracy\t0.80\tmacro f1\t0.80\n",
      "<class 'sklearn.svm.classes.SVC'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.51\tmacro f1\t0.34\n",
      "accuracy\t0.46\tmacro f1\t0.31\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "accuracy\t0.99\tmacro f1\t0.99\n",
      "accuracy\t0.74\tmacro f1\t0.74\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(binary=True)\n",
    "\n",
    "for clf in clfs:\n",
    "    print(str(clf.__class__))\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', vect),\n",
    "        ('clf', clf),\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print_short_eval(pipeline, X_train, y_train)\n",
    "    print_short_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los mejores modelos parecen ser la regresión logística y la SVM con kernel lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vecctorizador TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "accuracy\t0.87\tmacro f1\t0.87\n",
      "accuracy\t0.76\tmacro f1\t0.76\n",
      "<class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "accuracy\t0.99\tmacro f1\t0.99\n",
      "accuracy\t0.81\tmacro f1\t0.81\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "accuracy\t1.00\tmacro f1\t1.00\n",
      "accuracy\t0.56\tmacro f1\t0.56\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "accuracy\t0.99\tmacro f1\t0.99\n",
      "accuracy\t0.82\tmacro f1\t0.82\n",
      "<class 'sklearn.svm.classes.LinearSVC'>\n",
      "accuracy\t1.00\tmacro f1\t1.00\n",
      "accuracy\t0.84\tmacro f1\t0.84\n",
      "<class 'sklearn.svm.classes.SVC'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.51\tmacro f1\t0.34\n",
      "accuracy\t0.46\tmacro f1\t0.31\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "accuracy\t0.99\tmacro f1\t0.99\n",
      "accuracy\t0.65\tmacro f1\t0.63\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(binary=True)\n",
    "\n",
    "for clf in clfs:\n",
    "    print(str(clf.__class__))\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', vect),\n",
    "        ('clf', clf),\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print_short_eval(pipeline, X_train, y_train)\n",
    "    print_short_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedaremos con con el TfidfVectorizer y la SVM con kernel lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.84\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.88      0.82      0.85       146\n",
      "        pos       0.80      0.87      0.83       122\n",
      "\n",
      "avg / total       0.84      0.84      0.84       268\n",
      "\n",
      "[[119  27]\n",
      " [ 16 106]]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(binary=True)),\n",
    "    ('clf', LinearSVC(random_state=0)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "print_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test con algo nuestro nuevamente..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this is bad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this is good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this is very very good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this movie is not bad, it is good'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizador\n",
    "\n",
    "Primero hagamos un estudio superficial para ver qué parámetros vale la pena analizar.\n",
    "\n",
    "### Rango de n-gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.84\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.88      0.82      0.84       146\n",
      "        pos       0.80      0.86      0.83       122\n",
      "\n",
      "avg / total       0.84      0.84      0.84       268\n",
      "\n",
      "[[119  27]\n",
      " [ 17 105]]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(\n",
    "        binary=True,\n",
    "        ngram_range=(1, 2),\n",
    "    )),\n",
    "    ('clf', LinearSVC(random_state=0)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "print_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.84\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.86      0.85      0.86       146\n",
      "        pos       0.82      0.84      0.83       122\n",
      "\n",
      "avg / total       0.84      0.84      0.84       268\n",
      "\n",
      "[[124  22]\n",
      " [ 20 102]]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(\n",
    "        binary=True,\n",
    "        min_df=7,\n",
    "    )),\n",
    "    ('clf', LinearSVC(random_state=0)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "print_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.84\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.88      0.82      0.85       146\n",
      "        pos       0.80      0.87      0.83       122\n",
      "\n",
      "avg / total       0.84      0.84      0.84       268\n",
      "\n",
      "[[119  27]\n",
      " [ 16 106]]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(\n",
    "        binary=True,\n",
    "        max_df=0.95,\n",
    "    )),\n",
    "    ('clf', LinearSVC(random_state=0)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "print_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.84\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.90      0.78      0.84       146\n",
      "        pos       0.77      0.90      0.83       122\n",
      "\n",
      "avg / total       0.85      0.84      0.84       268\n",
      "\n",
      "[[114  32]\n",
      " [ 12 110]]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(\n",
    "        binary=True,\n",
    "        stop_words='english',\n",
    "    )),\n",
    "    ('clf', LinearSVC(random_state=0)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "print_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid-Search en Development\n",
    "\n",
    "Probemos muchas las combinaciones posibles de valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "param_grid = {\n",
    "    'vect__binary': [True],\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
    "    'vect__min_df': [6, 7, 14, 15],\n",
    "    'vect__max_df': [0.95, 0.9, 0.8],\n",
    "    'clf__random_state': [0],\n",
    "}\n",
    "\n",
    "params_list = list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from util import eval\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "results = []\n",
    "for params in params_list:\n",
    "    # TODO: add progress bar!\n",
    "    pipeline.set_params(**params)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    result = eval(pipeline, X_dev, y_dev)\n",
    "    \n",
    "    results.append({\n",
    "        **result,\n",
    "        **params,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>clf__random_state</th>\n",
       "      <th>f1</th>\n",
       "      <th>vect__binary</th>\n",
       "      <th>vect__max_df</th>\n",
       "      <th>vect__min_df</th>\n",
       "      <th>vect__ngram_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.861940</td>\n",
       "      <td>0</td>\n",
       "      <td>0.861243</td>\n",
       "      <td>True</td>\n",
       "      <td>0.95</td>\n",
       "      <td>6</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.861940</td>\n",
       "      <td>0</td>\n",
       "      <td>0.861243</td>\n",
       "      <td>True</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.861940</td>\n",
       "      <td>0</td>\n",
       "      <td>0.861243</td>\n",
       "      <td>True</td>\n",
       "      <td>0.80</td>\n",
       "      <td>6</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.858209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.857566</td>\n",
       "      <td>True</td>\n",
       "      <td>0.80</td>\n",
       "      <td>6</td>\n",
       "      <td>(1, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.858209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.857415</td>\n",
       "      <td>True</td>\n",
       "      <td>0.95</td>\n",
       "      <td>6</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.858209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.857415</td>\n",
       "      <td>True</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.858209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.857415</td>\n",
       "      <td>True</td>\n",
       "      <td>0.90</td>\n",
       "      <td>7</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.858209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.857415</td>\n",
       "      <td>True</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.854478</td>\n",
       "      <td>0</td>\n",
       "      <td>0.853890</td>\n",
       "      <td>True</td>\n",
       "      <td>0.80</td>\n",
       "      <td>6</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.854478</td>\n",
       "      <td>0</td>\n",
       "      <td>0.853742</td>\n",
       "      <td>True</td>\n",
       "      <td>0.95</td>\n",
       "      <td>7</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         acc  clf__random_state        f1  vect__binary  vect__max_df  \\\n",
       "1   0.861940                  0  0.861243          True          0.95   \n",
       "17  0.861940                  0  0.861243          True          0.90   \n",
       "33  0.861940                  0  0.861243          True          0.80   \n",
       "35  0.858209                  0  0.857566          True          0.80   \n",
       "2   0.858209                  0  0.857415          True          0.95   \n",
       "18  0.858209                  0  0.857415          True          0.90   \n",
       "21  0.858209                  0  0.857415          True          0.90   \n",
       "37  0.858209                  0  0.857415          True          0.80   \n",
       "34  0.854478                  0  0.853890          True          0.80   \n",
       "5   0.854478                  0  0.853742          True          0.95   \n",
       "\n",
       "    vect__min_df vect__ngram_range  \n",
       "1              6            (1, 2)  \n",
       "17             6            (1, 2)  \n",
       "33             6            (1, 2)  \n",
       "35             6            (1, 4)  \n",
       "2              6            (1, 3)  \n",
       "18             6            (1, 3)  \n",
       "21             7            (1, 2)  \n",
       "37             7            (1, 2)  \n",
       "34             6            (1, 3)  \n",
       "5              7            (1, 2)  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(['acc', 'f1'], ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomaremos la primer configuración..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.86\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.89      0.86      0.87       146\n",
      "        pos       0.83      0.87      0.85       122\n",
      "\n",
      "avg / total       0.86      0.86      0.86       268\n",
      "\n",
      "[[125  21]\n",
      " [ 16 106]]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(\n",
    "        binary=True,\n",
    "        min_df=6,\n",
    "        max_df=0.95,\n",
    "        ngram_range=(1, 2)\n",
    "    )),\n",
    "    ('clf', LinearSVC(random_state=0)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "print_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test con algo nuestro nuevamente..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this is bad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this is good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this is very very good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this movie is not bad, it is good'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incorporar Lexicon\n",
    "\n",
    "La idea es incorporar información externa acerca de la presencia de palabras positivas y negativas.\n",
    "\n",
    "Prbamos con:\n",
    "- https://mpqa.cs.pitt.edu/lexicons/subj_lexicon/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'subjectivity_clues_hltemnlp05/subjclueslen1-HLTEMNLP05.tff'\n",
    "f = open(filename)\n",
    "lines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for line in lines:\n",
    "    sline = line.split()\n",
    "    dline = dict([token.split('=') for token in sline if '=' in token])\n",
    "    word = dline['word1']\n",
    "    pol = dline['priorpolarity']\n",
    "    if pol not in {'both', 'neutral'}:\n",
    "        if pol in {'negative', 'weakneg'}:\n",
    "            pol = 'NEG'\n",
    "        else:\n",
    "            pol = 'POS'\n",
    "        words.append((word, pol))\n",
    "\n",
    "word_dict = dict(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuevo Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkn = TfidfVectorizer().build_tokenizer()\n",
    "def my_tkn(s):\n",
    "    tokens = tkn(s)\n",
    "    return [word_dict.get(token, token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NEG', 'and', 'POS']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tkn('bad and good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function my_tkn at 0x000000090967E6A8>, use_idf=True,\n",
       "        vocabulary=['POS', 'NEG'])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = TfidfVectorizer(vocabulary=['POS', 'NEG'], tokenizer=my_tkn)\n",
    "vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70022702, 0.71392024],\n",
       "       [0.6937695 , 0.72019711],\n",
       "       [0.98918182, 0.14669464],\n",
       "       [0.63669951, 0.77111201],\n",
       "       [0.90437497, 0.42673869],\n",
       "       [0.97911993, 0.20328346],\n",
       "       [0.887563  , 0.46068637],\n",
       "       [0.72890887, 0.68461074],\n",
       "       [0.80326737, 0.59561861],\n",
       "       [0.77492011, 0.63205919]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.transform(X_train[:10]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.84\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.87      0.82      0.85       146\n",
      "        pos       0.80      0.85      0.83       122\n",
      "\n",
      "avg / total       0.84      0.84      0.84       268\n",
      "\n",
      "[[120  26]\n",
      " [ 18 104]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', FeatureUnion([\n",
    "        ('bow', TfidfVectorizer(\n",
    "        binary=True,\n",
    "        min_df=5,\n",
    "        max_df=0.95,\n",
    "        ngram_range=(1, 3)\n",
    "    )),\n",
    "        ('pol',  TfidfVectorizer(vocabulary=['POS', 'NEG'], tokenizer=my_tkn)),\n",
    "    ])),\n",
    "    ('clf', LinearSVC(random_state=0)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "print_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['They absolutely loved it'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporar el Lexicon no nos ayudo demasiado, entonces no quedamos con..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.86\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.88      0.86      0.87       146\n",
      "        pos       0.84      0.86      0.85       122\n",
      "\n",
      "avg / total       0.86      0.86      0.86       268\n",
      "\n",
      "[[126  20]\n",
      " [ 17 105]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from util import print_eval\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(\n",
    "        binary=True,\n",
    "        min_df=5,\n",
    "        max_df=0.95,\n",
    "        ngram_range=(1, 2)\n",
    "    )),\n",
    "    ('clf', LinearSVC(random_state=0)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "print_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluamos en test y guardamos el modelo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import errno\n",
    "\n",
    "myFiles = []\n",
    "myPred = []\n",
    "\n",
    "path = 'test_reviews_sentoken/*.txt'\n",
    "files = glob.glob(path)\n",
    "index = 0\n",
    "for name in files:\n",
    "    try:\n",
    "        with open(name) as f:\n",
    "            y_pred = pipeline.predict(f)\n",
    "            myFiles.append(name)\n",
    "            myPred.append(str(y_pred).replace(\"[\", \"\").replace(\"]\", \"\"))\n",
    "    except IOError as exc:\n",
    "        if exc.errno != errno.EISDIR:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.txt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.txt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id Category\n",
       "0    0.txt        0\n",
       "1    1.txt        1\n",
       "2   10.txt        0\n",
       "3  100.txt        1\n",
       "4  101.txt        0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data={\"Id\": myFiles, \"Category\": myPred})\n",
    "df['Id'] = df['Id'].str.replace('\\\\','')\n",
    "df['Id'] = df['Id'].str.replace('test_reviews_sentoken','')\n",
    "df = df[[\"Id\", \"Category\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./file.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
